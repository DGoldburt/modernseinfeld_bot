{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ww_ZBkRuyGJ"
   },
   "source": [
    "# SECTION 1: Introduction\n",
    "\n",
    "Welcome to my NLP project using GPT-3 and Seinfeld data. The goal is to allow the user to prompt GPT-3 with something and have it respond with an AI-generated Seinfeld situation.\n",
    "\n",
    "Example:\n",
    "> Prompt: \"Trying to connect to WiFi\"  \n",
    "> Response: \"When the WiFi George usually steals suddenly has a password, he becomes addicted to trying to \"hack\" in. J: 'Just get your own!' G: 'NEVER' \"\n",
    "(This example response is from the @ModernSeinfeld twitter feed.)\n",
    "\n",
    "Setup:\n",
    "- This notebook probably won't work as-is on Colab. My local dev environment was jupyter notebook with a miniconda 4.11.0 python environment, run on a macbook\n",
    "- You'll need an OpenAI API key. Save this either to your Google drive in ./data/GPT3_api.key or in an .env file in the working directory\n",
    "- The data is saved in ./data. You can use the ScrapeTwitter_ModernSeinfeld notebook to see how the tweets were gathered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmRjTL4myYC2"
   },
   "source": [
    "\n",
    "# SECTION 2: Data\n",
    "\n",
    "The data used is:\n",
    "\n",
    "\n",
    "*   Seinfeld episodes synopsis (173), from imdb and scraped here: https://www.kaggle.com/bcruise/seinfeld-episodes\n",
    "*   @ModernSeinfeld tweets (492), scraped using twint in the acompanying notebook\n",
    "*   Curb Your Enthusiasm episode synopsis, might be interesting to add later for more of a \"Larry David\" bot\n",
    "\n",
    "With a combined 565 examples, we should have enough data to fine-tune GPT-3. According to the OpenAI guide <https://beta.openai.com/docs/guides/fine-tuning>, \"we recommend having at least a couple hundred examples. In general, we've found that each doubling of the dataset size leads to a linear increase in model quality.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title    173\n",
      "desc     173\n",
      "dtype: int64\n",
      "                 title                                               desc\n",
      "0  Good News, Bad News  Jerry and George argue whether an overnight vi... \n",
      "\n",
      "                                               tweet\n",
      "0  George's GF wants a \"no phones at dinner\" rule...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "episodes_df = pd.read_csv('./data/seinfeld_imdb.csv.xls',usecols=['title','desc'])\n",
    "tweets_df = pd.read_csv('./data/SeinfeldToday_tweets.csv',usecols=['tweet'], skiprows=[1])\n",
    "print(episodes_df.count())\n",
    "\n",
    "print(episodes_df.head(1), \"\\n\")\n",
    "print(tweets_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 3: Working with Open AI and GPT3\n",
    "\n",
    "- First we load the API Key\n",
    "- Then we fine-tune a model, following https://beta.openai.com/docs/guides/fine-tuning\n",
    "- Then we test prompting the model with something and seeing what Seinfeldy situation it comes up with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "83NW3EbHyblr",
    "outputId": "0a5135a5-1896-483c-b8ab-b650cfb1eca2"
   },
   "outputs": [],
   "source": [
    "!pip -q install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fMBfq3k6ywa4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYHnb3_QyzYg",
    "outputId": "d9ceb7c1-dc9e-414f-fa05-f0a46ad72c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/dan/dev/miniconda3/lib/python3.9/site-packages (0.19.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Load OpenAI API Key\n",
    "\n",
    "try:\n",
    "  # When in Colab\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  with open(\"/content/drive/My Drive/Colab Notebooks/GPT3_api\", 'r') as file:\n",
    "    openai.api_key = file.read().rstrip('\\n')\n",
    "except:\n",
    "  # When in local dev environment\n",
    "  try:\n",
    "     # Load variables from .env file in working directory\n",
    "     !pip install python-dotenv\n",
    "     from dotenv import load_dotenv\n",
    "     load_dotenv()\n",
    "  except:\n",
    "     # You'll need to set the environment variables somehow, perhaps in .bashrc\n",
    "     print(\"Warning: .env file not found\")\n",
    "  API_KEY = os.getenv('PROJECT_API_KEY')\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R55jALEc9IiB",
    "outputId": "ccd142cb-59a9-4d81-c342-23eaa26d9ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"length\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\nThis is a test\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1644344165,\n",
      "  \"id\": \"cmpl-4ZPK1Y6D34H8YooQRTdNznDCfDhvS\",\n",
      "  \"model\": \"text-davinci:001\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI API\n",
    "response = openai.Completion.create(engine=\"text-davinci-001\", prompt=\"Say this is a test\", max_tokens=6)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlQiyIz4NR7C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMLfP4YFWnKfytVMOq0uUOc",
   "mount_file_id": "16xcsyKi8vCBHGntbHljNFp77ranRAG83",
   "name": "GPT3 Seinfeld.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
