{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afdeec0f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The idea is to have a twitter bot that allows users to tweet prompts @modernseinfeld_bot and receive a reply with the completion\n",
    "\n",
    "The Twitter API requires that all requests use OAuth to authenticate. Once you sign up for twitter's developer platform https://developer.twitter.com/ you will get the required authentication credentials to be able to use the API. These credentials are three text strings:\n",
    "\n",
    "- API key (token)\n",
    "- API secret\n",
    "- Bearer token\n",
    "\n",
    "I store these in the .env file of the main project directory. This file is never checked into GitHub (by means of the .ignore file). We use load_dotenv() to load the required keys into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398829c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except:\n",
    "    !pip install python-dotenv\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "load_dotenv(override=True)\n",
    "BEARER_TOKEN = os.getenv('TWITTER_BEARER_TOKEN')\n",
    "CONSUMER_KEY = os.getenv('TWITTER_API_KEY')\n",
    "CONSUMER_SECRET = os.getenv('TWITTER_API_SECRET')\n",
    "ACCESS_TOKEN = os.getenv('TWITTER_ACCESS_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "FINE_TUNED_MODEL = \"curie:ft-personal-2022-02-16-02-07-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9e9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"id\":\"20\",\"text\":\"just setting up my twttr\"}}"
     ]
    }
   ],
   "source": [
    "!curl -X GET -H \"Authorization: Bearer {BEARER_TOKEN}\" \"https://api.twitter.com/2/tweets/20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X GET -H \"Authorization: Bearer {BEARER_TOKEN}\" \"https://api.twitter.com/2/tweets/20?expansions=author_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d357940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tweepy\n",
    "except: \n",
    "    !pip -qq install tweepy=4.6.0\n",
    "    import tweepy\n",
    "\n",
    "#print(tweepy.__version__)\n",
    "\n",
    "# Tweepy version 4.6.0 added support for APIv2 filtered streaming\n",
    "# via StreamingClient where you can add a rule\n",
    "# e.g. streaming_client.add_rules(tweepy.StreamRule(\"@SeinfeldPlotBot\"))\n",
    "# Note our development account only has access to use Twitter API v2\n",
    "\n",
    "# To connect as the user\n",
    "client_user = tweepy.Client(\n",
    "    consumer_key=CONSUMER_KEY, consumer_secret=CONSUMER_SECRET,\n",
    "    access_token=ACCESS_TOKEN, access_token_secret=ACCESS_TOKEN_SECRET\n",
    ")\n",
    "# To connect as the app\n",
    "client_app = tweepy.Client(BEARER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52c053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import openai\n",
    "except:\n",
    "    !pip -qq install openai\n",
    "    import openai\n",
    "    \n",
    "def call_GPT3(prompt: str) -> str:\n",
    "    \"\"\"\\\n",
    "    Prompt our fine-tuned GPT-3 model and return the response.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): the prompt part of the answer. Must be less than 55 charachters.\n",
    "    \n",
    "    Returns:\n",
    "        str: the prompt plus the completion from GPT3     \n",
    "    \"\"\"\n",
    "    openai.api_key = OPENAI_KEY\n",
    "    # We strip the completions of the stop token from training\n",
    "    STOP_TOKEN = \" ##END##\"\n",
    "    assert len(prompt) < 55\n",
    "\n",
    "    #TODO Handle RateLimitError. For some reason the first API call after a long break will always raise this\n",
    "    completion = openai.Completion.create(\n",
    "        model=FINE_TUNED_MODEL,\n",
    "        prompt=prompt,\n",
    "        best_of = 8, #returns the \"best\" of 5 server-side completions (the one with the lowest log probability per token)\n",
    "        n=1,\n",
    "        max_tokens = 55)['choices'][0]\n",
    "    \n",
    "    return prompt + completion['text'].replace('\\t','',-1).replace(str(STOP_TOKEN),\"\",-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9aaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_reply(text: str, tweet_id_to_reply: str) -> str:\n",
    "    \"\"\"\\\n",
    "    Reply to the mentioner with the text response.\n",
    "    \n",
    "    Args:\n",
    "        text (str): the text of the tweet\n",
    "        tweet_id_to_reply (str): the tweet to reply to\n",
    "    \n",
    "    Returns:\n",
    "        str: the id of the reply tweet      \n",
    "    \"\"\"\n",
    "    \n",
    "    response = client_user.create_tweet(\n",
    "        in_reply_to_tweet_id = tweet_id_to_reply,\n",
    "        text=text\n",
    "    )\n",
    "    return f\"https://twitter.com/user/status/{response.data['id']}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e9ad401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SeinfeldPlotBot user_id is 1494776018313392130\n"
     ]
    }
   ],
   "source": [
    "# Manually poll to get mentions of SeinfeldPlotBot\n",
    "user_id = client_app.get_user(username='SeinfeldPlotBot').data.id\n",
    "print(\"The SeinfeldPlotBot user_id is {}\".format(user_id))\n",
    "response = client.get_users_mentions(user_id, tweet_fields=[\"author_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc341903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author_id': '1494776018313392130', 'id': '1496299981627707395', 'text': '@SeinfeldPlotBot test'}\n",
      "Replied with  test auditions for America's Next Top Model. Kramer tries to \"stunt,\" but his friend the limo driver leaks his identity. ## in this tweet: https://twitter.com/user/status/1496592947797794826\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the polled responses and call GPT3\n",
    "for tweet in response.data:\n",
    "    print(tweet.data)\n",
    "    prompt = tweet.data['text'].lstrip(\"@SeinfeldPlotBot\")\n",
    "    completion = call_GPT3(prompt)\n",
    "    response = tweet_reply(completion, tweet.data['id'])\n",
    "    print(f\"Replied with {completion} in this tweet: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42099701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1498744649309118470', 'text': '@SeinfeldPlotBot Kramer goes to his reunion'}\n",
      "Replied with  Kramer goes to his reunion dressed as a woman. \"I didn't know how else to stand out!\" in this tweet: https://twitter.com/user/status/1498744702463578112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream encountered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dan/dev/miniconda3/lib/python3.9/site-packages/tweepy/streaming.py\", line 91, in _connect\n",
      "    self.on_data(line)\n",
      "  File \"/Users/dan/dev/miniconda3/lib/python3.9/site-packages/tweepy/streaming.py\", line 870, in on_data\n",
      "    self.on_tweet(tweet)\n",
      "  File \"<ipython-input-11-3f8a3f241dfd>\", line 9, in on_tweet\n",
      "    completion = call_GPT3(prompt)\n",
      "  File \"<ipython-input-5-a443dad276c4>\", line 20, in call_GPT3\n",
      "    assert len(prompt) < 55\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1498744702463578112', 'text': 'Kramer goes to his reunion dressed as a woman. \"I didn\\'t know how else to stand out!\"'}\n"
     ]
    }
   ],
   "source": [
    "# Create a filtered stream\n",
    "\n",
    "# Customize the on_tweet handler to call GPT3\n",
    "class streaming_mentions(tweepy.StreamingClient):\n",
    "\n",
    "    def on_tweet(self, tweet):\n",
    "        print(tweet.data)\n",
    "        prompt = tweet.data['text'].lstrip(\"@SeinfeldPlotBot\")\n",
    "        completion = call_GPT3(prompt)\n",
    "        response = tweet_reply(completion, tweet.data['id'])\n",
    "        print(f\"Replied with {completion} in this tweet: {response}\")\n",
    "\n",
    "streaming_client = streaming_mentions(BEARER_TOKEN)\n",
    "streaming_client.add_rules(tweepy.StreamRule(\"@SeinfeldPlotBot has:mention -is:retweet -is:reply -is:quote\"))\n",
    "\n",
    "#Launch the stream\n",
    "streaming_client.filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac481af",
   "metadata": {},
   "source": [
    "### Findings\n",
    "1. OpenAI tends to give you a RateLimit error the first time you call your model after a long time. Should be handled with a retry\n",
    "2. Twitter streaming filter returns replies to mentions, even if you try to exclude this in the rule. This means that the bot's own response gets picked up as a new prompt. This should be handled in the code (since it can't be in the rule)\n",
    "3. MOST IMPORTANTLY, OpenAI restricts this use case from going live. They have a mandatory go-live review if you're going to open up to more than 3 users. I submitted an application along with a video overview of my application. They got back to me in a couple of days and were very nice about it, but could not approve my twitterbot. According to their usage guidelines https://beta.openai.com/docs/usage-guidelines/twitter, introducing synthetic content into society is too risky. \"All applications that involve social media must require a human to manually review and post the content. No automated or scheduled posting. Tweet generation and Instagram post generation are disallowed.\"\n",
    "4. THUS, see the WebUI_FastAPI notebook. This is the UI I'm working on and will submit as my go-live application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d167db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
